{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Colletion\n",
    "\n",
    "For my project, I collected data from a company called Robinhood, which specializes in offering its users the ability to invest in stocks without having to pay any commissions on the transactions. On their website, they have collections of stocks listed with various information about each one, including the stock ticker, price, analyst ratings, etc. I downloaded the html files of each of these collections and as you can see below, I read them all in along with all of the information that Robinhood provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "files = [\"Consumer\", \"Energy\", \"Entertainment\", \"Finance\", \"Health\",\n",
    "        \"Manufacturing\", \"Oil:Gas\", \"SocialMedia\", \"Software\", \"Tech\"]\n",
    "rows = []\n",
    "\n",
    "for file in files:\n",
    "    filename = file + \".htm\"\n",
    "    f = codecs.open(filename, 'r')\n",
    "    soup = BeautifulSoup(f.read(), \"html.parser\")\n",
    "    tables = soup.find_all(\"table\")\n",
    "    stock_data = tables[0]\n",
    "    \n",
    "    for stock in stock_data.find_all(\"tr\", {\"class\":\"_3-Fg9lFlzey28mCJClXXxZ\"}):\n",
    "        name = stock.find(\"div\", {\"class\":\"_2fMBL180hIqVoxOuNVJgST\"}).text\n",
    "        symbol = stock.find(\"span\").text\n",
    "        price = stock.find_all(\"div\")[4].text\n",
    "        market_cap = stock.find_all(\"div\")[7].text\n",
    "        owners = stock.find(\"div\", {\"class\":\"OJSR51UkZBkOak0WhbWKn\"}).text\n",
    "        rating = stock.find_all(\"div\")[10].text\n",
    "        rows.append({\n",
    "        \"Company\": name,\n",
    "        \"Ticker\": symbol,\n",
    "        \"Price\": price, \n",
    "        \"MarketCap\": market_cap,\n",
    "        \"Popularity\": owners,\n",
    "        \"Rating\": rating,\n",
    "        \"Sector\": file\n",
    "        })\n",
    "    \n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I set the stock ticker as the index since this should be unique to each stock, and then I transformed the quantitative variables to their correct forms. The Market Cap of a stock was given in millions or billions with corresponding \"M\"'s and \"B\"'s at the end of the number, so I had to convert these to numeric as well. Then I made a bivariate variable for each of the possible sectors to determine if a stock is classified under a specific sector, and a stock can be classified under multiple sectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh = df.set_index(\"Ticker\").replace(\"â€”\", np.nan)\n",
    "rh[\"Popularity\"] = rh['Popularity'].astype(str\n",
    "            ).str.replace(\",\", \"\").astype(float)\n",
    "rh[\"Price\"] = rh[\"Price\"].astype(str).str.replace(\"$\", \"\"\n",
    "                    ).str.replace(\",\", \"\").astype(float)\n",
    "\n",
    "def mc_to_float(mc):\n",
    "    billion = True\n",
    "    if \"M\" in mc:\n",
    "        billion = False\n",
    "    if billion:\n",
    "        return float(mc.replace(\"B\", \"\")) * 1000000\n",
    "    else:\n",
    "        return float(mc.replace(\"M\", \"\")) * 1000\n",
    "    \n",
    "rh[\"MarketCap\"] = rh[\"MarketCap\"].astype(str).apply(mc_to_float)\n",
    "rh[\"Rating\"] = pd.to_numeric(rh[\"Rating\"].str.replace(\"% Buy\",\"\"))\n",
    "\n",
    "sectors = pd.get_dummies(rh[\"Sector\"]).groupby(rh.index).sum()\n",
    "rh = rh.drop_duplicates().merge(sectors, how=\"inner\", left_index=True,\n",
    "        right_index=True).drop(\"Sector\", axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MarketWatch.com displays the change in price of a stock for various intervals, so for each stock, I retrieved the change in price over the past five days, month, three months, and year. I also got the volume traded per day as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "resp = requests.get(\"https://www.marketwatch.com/investing/stock/aapl\")\n",
    "soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "\n",
    "five_day = []\n",
    "month = []\n",
    "three_month = []\n",
    "year = []\n",
    "volumes = []\n",
    "\n",
    "for ticker in rh.index:\n",
    "    resp = requests.get(\"https://www.marketwatch.com/investing/stock/\" + ticker)\n",
    "    soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "    changes = soup.findAll(\"li\", {\"class\":\"content__item value ignore-color\"})\n",
    "    print(ticker)\n",
    "    if (len(changes) > 1):\n",
    "        five_day.append(changes[0].text)\n",
    "        month.append(changes[1].text)\n",
    "    else:\n",
    "        five_day.append(\"NA\")\n",
    "        month.append(\"NA\")\n",
    "    if (len(changes) > 4):\n",
    "        three_month.append(changes[2].text)\n",
    "        year.append(changes[4].text) \n",
    "    else:\n",
    "        three_month.append(\"NA\")\n",
    "        year.append(\"NA\")\n",
    "    if len(soup.findAll(\"span\", {\"class\":\"kv__primary\"})) > 0:\n",
    "        volumes.append(soup.findAll(\"span\", {\"class\":\"kv__primary\"})[-1].text)\n",
    "    else:\n",
    "        volumes.append(\"NA\")\n",
    "    time.sleep(.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh[\"Year\"] = year\n",
    "rh[\"Three_Month\"] = three_month\n",
    "rh[\"Month\"] = month\n",
    "rh[\"Five_Day\"] = five_day\n",
    "rh[\"Year\"] = pd.to_numeric(rh[\"Year\"].str.replace(\"%\",\"\"), errors=\"coerce\")\n",
    "rh[\"Month\"] = pd.to_numeric(rh[\"Month\"].str.replace(\"%\",\"\"), errors=\"coerce\")\n",
    "rh[\"Three_Month\"] = pd.to_numeric(rh[\"Three_Month\"].str.replace(\"%\",\"\"), errors=\"coerce\")\n",
    "rh[\"Five_Day\"] = pd.to_numeric(rh[\"Five_Day\"].str.replace(\"%\",\"\"), errors=\"coerce\")\n",
    "rh[\"Volume\"] = volumes\n",
    "\n",
    "def transform_volume(volume):\n",
    "    if \"M\" in volume:\n",
    "        return float(volume.replace(\"M\", \"\")) * 1000000\n",
    "    if \"K\" in volume:\n",
    "        return float(volume.replace(\"K\", \"\")) * 1000\n",
    "    return float(volume)\n",
    "\n",
    "rh[\"Volume\"] = rh[\"Volume\"].apply(transform_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yahoo Finance gives a description of each company based off of it's ticker, so I was also able to get this textual data for each individual stock. I was able to use these company descriptions to create some variables which stated whether or not the given stock's description contained a specified keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    }
   ],
   "source": [
    "descriptions = []\n",
    "\n",
    "for ticker in rh.index:\n",
    "    resp = requests.get(\"https://finance.yahoo.com/quote/%s/profile?p=%s\"%(ticker,ticker))\n",
    "    soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "    desc = soup.findAll(\"p\", {\"class\":\"Mt(15px) Lh(1.6)\"})\n",
    "    if len(desc) > 0:\n",
    "        descriptions.append(desc[0].text)\n",
    "    else:\n",
    "        descriptions.append(\"NA\")\n",
    "    time.sleep(.1)\n",
    "    \n",
    "rh[\"Description\"] = descriptions\n",
    "\n",
    "keywords = [\"machine learning\", \"artificial intelligence\",\n",
    "            \"robotics\", \"gaming\", \"software\", \"solar\", \"cannabis\"]\n",
    "\n",
    "for keyword in keywords:\n",
    "    rh[keyword] = rh.Description.str.lower().str.contains(keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found out that MarketWatch also gives the location of the headquarters of each company, so I was able to get the address of each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh.to_csv(\"temp.csv\")\n",
    "\n",
    "addresses = []\n",
    "for ticker in rh.index:\n",
    "    resp = requests.get(\"https://www.marketwatch.com/investing/stock/%s/profile\"%ticker)\n",
    "    soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "    addy = soup.findAll(\"div\", {\"companyinfo fourwide\"})\n",
    "    if len(addy) > 0:\n",
    "        addresses.append(addy[0])\n",
    "    else:\n",
    "        addresses.append(\"NA\")\n",
    "    time.sleep(.1)\n",
    "    print(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_add = []\n",
    "\n",
    "for address in addresses:\n",
    "    if len(address) > 4:\n",
    "        final_add.append(address.text.split(\"\\n\")[2] + \" \" + address.text.split(\"\\n\")[-3])\n",
    "    else:\n",
    "        final_add.append(\"NA\")\n",
    "        \n",
    "rh[\"Address\"] = final_add\n",
    "rh.to_csv(\"temp2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then found the geopy library, which allowed me to obtain a set of coordinates (longitude, latitude) for each of the addresses that I found above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "rh = pd.read_csv(\"temp2.csv\")\n",
    "\n",
    "longs = []\n",
    "lats = []\n",
    "\n",
    "count = 0\n",
    "for addy in rh.Address:\n",
    "    print(count)\n",
    "    geolocator = Nominatim(user_agent=\"project\")\n",
    "    location = geolocator.geocode(addy)\n",
    "    if location != None:\n",
    "        longs.append(location.longitude)\n",
    "        lats.append(location.latitude)\n",
    "    else:\n",
    "        longs.append(\"NA\")\n",
    "        lats.append(\"NA\")\n",
    "    count += 1\n",
    "\n",
    "rh[\"Longitude\"] = longs\n",
    "rh[\"Latitude\"] = lats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I wanted to get some info on the CEO of each company, so I used MarketWatch to get the age and name of the main director in charge of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh.to_csv(\"temp3.csv\")\n",
    "\n",
    "names = []\n",
    "ages = []\n",
    "\n",
    "for ticker in rh.index:\n",
    "    resp = requests.get(\"https://www.marketwatch.com/investing/stock/%s/profile\"%ticker)\n",
    "    soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "    if len(soup.findAll(\"td\", {\"class\":\"name\"})) > 0:\n",
    "        names.append(soup.findAll(\"td\", {\"class\":\"name\"})[0].text)\n",
    "    else:\n",
    "        names.append(\"NA\")\n",
    "    if len(soup.findAll(\"td\", {\"class\":\"age\"})) > 0:\n",
    "        ages.append(soup.findAll(\"td\", {\"class\":\"age\"})[0].text)\n",
    "    else:\n",
    "        ages.append(\"NA\")\n",
    "    print(ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I used the prefix of the CEO's names to determine the sex of the CEO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh[\"CEO_name\"] = names\n",
    "rh[\"CEO_age\"] = pd.to_numeric(ages, errors=\"coerce\")\n",
    "rh[\"CEO_sex\"] = rh[\"CEO_name\"].str.split().str[0].map({\n",
    "    \"Mr.\":0,\n",
    "    \"NA\":None,\n",
    "    \"Dr.\":None,\n",
    "    \"Ms.\":1,\n",
    "    \"Howard\":0,\n",
    "    \"Raj\":0,\n",
    "    \"Gary\":0,\n",
    "    \"GCP\":None,\n",
    "    \"John\":0,\n",
    "    \"Scott\":0,\n",
    "    \"Chesapeake\": None,\n",
    "    \"David\":0,\n",
    "    \"Jennifer\":1,\n",
    "    \"Michael\":0\n",
    "})\n",
    "\n",
    "rh[\"CEO_age\"] = pd.to_numeric(rh[\"CEO_age\"], errors=\"coerce\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, I looked at whether or not the stock ticker was an English word or not, so that I could later see if this influenced user's decisions on which stocks were the most appealing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enchant\n",
    "d = enchant.Dict(\"en_US\")\n",
    "rh[\"English_Word\"] = rh[\"Ticker\"].apply(d.check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh.to_csv(\"final.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
